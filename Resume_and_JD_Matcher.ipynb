{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2d984e-026c-408b-9632-45184a393c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.7.2)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.2-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.9.1-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (6.0.3)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anubh\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-5.1.2-py3-none-any.whl (488 kB)\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/12.0 MB 9.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 5.0/12.0 MB 13.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.8/12.0 MB 8.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.1/12.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.0 MB 6.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.0 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 5.7 MB/s  0:00:02\n",
      "Downloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "   ---------------------------------------- 0.0/566.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 566.1/566.1 kB 4.8 MB/s  0:00:00\n",
      "Downloading tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.6/2.7 MB 6.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 2.1/2.7 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 3.9 MB/s  0:00:00\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
      "Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Downloading safetensors-0.6.2-cp38-abi3-win_amd64.whl (320 kB)\n",
      "Downloading torch-2.9.1-cp311-cp311-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.8/111.0 MB 12.6 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 3.1/111.0 MB 7.1 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 3.7/111.0 MB 6.8 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 4.2/111.0 MB 4.7 MB/s eta 0:00:23\n",
      "   - -------------------------------------- 5.2/111.0 MB 5.7 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 6.6/111.0 MB 5.2 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 6.6/111.0 MB 5.2 MB/s eta 0:00:20\n",
      "   -- ------------------------------------- 8.1/111.0 MB 5.0 MB/s eta 0:00:21\n",
      "   --- ------------------------------------ 8.9/111.0 MB 4.6 MB/s eta 0:00:23\n",
      "   --- ------------------------------------ 10.5/111.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 11.3/111.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 12.3/111.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ---- ----------------------------------- 12.3/111.0 MB 4.9 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.2/111.0 MB 4.7 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 14.7/111.0 MB 4.8 MB/s eta 0:00:21\n",
      "   ----- ---------------------------------- 15.2/111.0 MB 4.4 MB/s eta 0:00:22\n",
      "   ------ --------------------------------- 17.0/111.0 MB 4.7 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 17.0/111.0 MB 4.7 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 18.6/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   ------ --------------------------------- 18.6/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 20.7/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   ------- -------------------------------- 21.0/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 22.5/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 23.1/111.0 MB 4.6 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 24.1/111.0 MB 4.5 MB/s eta 0:00:20\n",
      "   -------- ------------------------------- 24.9/111.0 MB 4.6 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 26.5/111.0 MB 4.6 MB/s eta 0:00:19\n",
      "   --------- ------------------------------ 26.7/111.0 MB 4.6 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 27.8/111.0 MB 4.5 MB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 29.1/111.0 MB 4.6 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 30.1/111.0 MB 4.6 MB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 30.1/111.0 MB 4.6 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 31.7/111.0 MB 4.5 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 32.2/111.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 33.6/111.0 MB 4.6 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 33.8/111.0 MB 4.4 MB/s eta 0:00:18\n",
      "   ------------ --------------------------- 35.7/111.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ------------ --------------------------- 35.7/111.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 37.2/111.0 MB 4.5 MB/s eta 0:00:17\n",
      "   ------------- -------------------------- 37.2/111.0 MB 4.5 MB/s eta 0:00:17\n",
      "   -------------- ------------------------- 39.3/111.0 MB 4.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 39.3/111.0 MB 4.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 40.9/111.0 MB 4.5 MB/s eta 0:00:16\n",
      "   -------------- ------------------------- 41.2/111.0 MB 4.4 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 43.0/111.0 MB 4.5 MB/s eta 0:00:16\n",
      "   --------------- ------------------------ 43.3/111.0 MB 4.5 MB/s eta 0:00:16\n",
      "   ---------------- ----------------------- 44.6/111.0 MB 4.4 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 45.1/111.0 MB 4.5 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 46.7/111.0 MB 4.5 MB/s eta 0:00:15\n",
      "   ---------------- ----------------------- 46.9/111.0 MB 4.5 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 48.5/111.0 MB 4.5 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 48.5/111.0 MB 4.5 MB/s eta 0:00:15\n",
      "   ----------------- ---------------------- 49.5/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 50.9/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------ --------------------- 51.4/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 53.0/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 53.0/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 54.0/111.0 MB 4.4 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 55.1/111.0 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 56.4/111.0 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 56.6/111.0 MB 4.4 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 58.2/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 58.2/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 59.8/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   --------------------- ------------------ 60.6/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 61.6/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 62.1/111.0 MB 4.4 MB/s eta 0:00:12\n",
      "   ---------------------- ----------------- 62.7/111.0 MB 4.3 MB/s eta 0:00:12\n",
      "   ----------------------- ---------------- 64.5/111.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 64.5/111.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 66.3/111.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 66.3/111.0 MB 4.4 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 68.2/111.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------ --------------- 68.9/111.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 69.5/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 70.5/111.0 MB 4.4 MB/s eta 0:00:10\n",
      "   ------------------------- -------------- 71.3/111.0 MB 4.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 72.6/111.0 MB 4.4 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 73.1/111.0 MB 4.3 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 75.0/111.0 MB 4.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 75.0/111.0 MB 4.4 MB/s eta 0:00:09\n",
      "   --------------------------- ------------ 76.8/111.0 MB 4.4 MB/s eta 0:00:08\n",
      "   --------------------------- ------------ 77.6/111.0 MB 4.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 77.9/111.0 MB 4.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.4/111.0 MB 4.4 MB/s eta 0:00:08\n",
      "   ---------------------------- ----------- 79.4/111.0 MB 4.4 MB/s eta 0:00:08\n",
      "   ----------------------------- ---------- 80.7/111.0 MB 4.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 81.8/111.0 MB 4.4 MB/s eta 0:00:07\n",
      "   ----------------------------- ---------- 82.8/111.0 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 83.4/111.0 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 84.7/111.0 MB 4.4 MB/s eta 0:00:07\n",
      "   ------------------------------ --------- 85.5/111.0 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------------ --------- 86.0/111.0 MB 4.3 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 87.0/111.0 MB 4.4 MB/s eta 0:00:06\n",
      "   ------------------------------- -------- 87.8/111.0 MB 4.3 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 89.7/111.0 MB 4.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 90.7/111.0 MB 4.4 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 90.7/111.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 92.5/111.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 93.1/111.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------------------------------- ------ 93.8/111.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 94.9/111.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 95.7/111.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 96.7/111.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 97.3/111.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 98.8/111.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ----------------------------------- ---- 99.1/111.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.4/111.0 MB 4.4 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 100.9/111.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------------------ --- 101.4/111.0 MB 4.3 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 103.5/111.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 103.5/111.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 105.4/111.0 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------------------------- -- 105.4/111.0 MB 4.4 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 107.2/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 107.5/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.1/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  109.6/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.6/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  110.9/111.0 MB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 111.0/111.0 MB 4.3 MB/s  0:00:25\n",
      "Downloading networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.3/2.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.1 MB/s  0:00:00\n",
      "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 2.4/6.3 MB 15.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.9/6.3 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 4.5/6.3 MB 7.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 5.5/6.3 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 4.4 MB/s  0:00:01\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "   ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 536.2/536.2 kB 17.1 MB/s  0:00:00\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, networkx, fsspec, filelock, torch, huggingface-hub, tokenizers, transformers, sentence-transformers\n",
      "\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   ---------- -----------------------------  3/12 [regex]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ---------------- -----------------------  5/12 [fsspec]\n",
      "   ---------------- -----------------------  5/12 [fsspec]\n",
      "   ---------------- -----------------------  5/12 [fsspec]\n",
      "   ---------------- -----------------------  5/12 [fsspec]\n",
      "   ---------------- -----------------------  5/12 [fsspec]\n",
      "   -------------------- -------------------  6/12 [filelock]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   ----------------------- ----------------  7/12 [torch]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   -------------------------- -------------  8/12 [huggingface-hub]\n",
      "   ------------------------------ ---------  9/12 [tokenizers]\n",
      "   ------------------------------ ---------  9/12 [tokenizers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   --------------------------------- ------ 10/12 [transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ------------------------------------ --- 11/12 [sentence-transformers]\n",
      "   ---------------------------------------- 12/12 [sentence-transformers]\n",
      "\n",
      "Successfully installed filelock-3.20.0 fsspec-2025.10.0 huggingface-hub-0.36.0 mpmath-1.3.0 networkx-3.5 regex-2025.11.3 safetensors-0.6.2 sentence-transformers-5.1.2 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts hf.exe, huggingface-cli.exe and tiny-agents.exe are installed in 'C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts transformers-cli.exe and transformers.exe are installed in 'C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2 numpy scikit-learn sentence-transformers transformers accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b28de5b-3ef9-4ba2-8c99-f57b8add46a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import PyPDF2\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "\n",
    "import time\n",
    "import csv\n",
    "from textwrap import shorten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6203dc4a-3b95-4cf1-bb18-a7429bee1248",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "rewriter = pipeline(\"text2text-generation\", model=\"google/flan-t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ca99e6d-73d7-4d14-affb-6f00d756822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of resume text:\n",
      " Anubhav Singh  \n",
      " anubhavsingh8003 @gmail .com   9536643996  \n",
      "Education  \n",
      "Thapar Institute of Engineering and Technology                                \n",
      "B.E. in Computer Engineering (COE)              \n",
      "Graduation  Year: 2026  \n",
      " \n",
      "Navjeevan Science School   \n",
      "Higher Secondary Certification  (96.8% ) \n",
      "Projects  \n",
      "SmartDoc AI  PDF Summarizer & Chatbot  | Python, Streamlit, HuggingFace, Transformers, OpenAI API  \n",
      " Built a web app to summarize PDFs and answer user queries using LLMs (T5 + OpenAI).  \n",
      "\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample of JD text:\n",
      "  \n",
      "Data  Engineer  P1 \n",
      "Primary Location:  Gurugram , India  \n",
      "About the Role:  \n",
      " \n",
      "We are seeking a skilled and motivated  Snowflake /SQL  Developer  to join our data engineering team. \n",
      "The ideal candidate will have hands -on experience in designing, developing, and optimizing data \n",
      "pipelines and solutions using Snowflake. You will work closely with cross -functional teams to support \n",
      "data -driven decision -making and ensure the scalability and performance of our data infrastructure.  \n",
      "Our tools in\n"
     ]
    }
   ],
   "source": [
    "def read_pdf(path: str) -> str:\n",
    "    text = []\n",
    "    with open(path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            page_text = page.extract_text() or \"\"\n",
    "            text.append(page_text)\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "resume_pdf_path =\"C:/Users/anubh/OneDrive/Documents/Anubhav_Singh_resume.pdf\"\n",
    "jd_pdf_path = \"C:/Users/anubh/OneDrive/Documents/Data_Engineer_JD.pdf\"\n",
    "\n",
    "resume_raw = read_pdf(resume_pdf_path)\n",
    "jd_raw = read_pdf(jd_pdf_path)\n",
    "\n",
    "print(\"Sample of resume text:\\n\", resume_raw[:500])\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Sample of JD text:\\n\", jd_raw[:500])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b6ca755-60dc-43c9-8089-677994f0d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18 resume bullets and 24 JD bullets.\n",
      "\n",
      "Sample resume bullets:\n",
      "- Anubhav Singh anubhavsingh8003 @gmail .com  9536643996 Education Thapar Institute of Engineering and Technology B.E.\n",
      "- in Computer Engineering (COE) Graduation Year: 2026 Navjeevan Science School Higher Secondary Certification (96.8% ) Projects SmartDoc AI  PDF Summarizer & Chatbot | Python, Streamlit, HuggingFace, Transformers, OpenAI API  Built a web app to summarize PDFs and answer user queries using LLMs (T5 + OpenAI).\n",
      "-  Achieved 90 95% summary accuracy with average processing time of <4 seconds per document.\n",
      "-  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "- Voice -Based Age & Gender Recognition | TensorFlow, LSTM, Librosa, Gradio  Built an LSTM -based system to classify speaker gender and age group (teens sixties) from voice clips.\n",
      "\n",
      "Sample JD bullets:\n",
      "- Data Engineer P1 Primary Location: Gurugram , India About the Role: We are seeking a skilled and motivated Snowflake /SQL Developer to join our data engineering team.\n",
      "- The ideal candidate will have hands -on experience in designing, developing, and optimizing data pipelines and solutions using Snowflake.\n",
      "- You will work closely with cross -functional teams to support data -driven decision -making and ensure the scalability and performance of our data infrastructure.\n",
      "- Our tools include Snowflake, SQL, Table au, Power BI Key Responsibilities :  Design and develop scalable data pipelines and ETL processes using Snowflake.\n",
      "-  Implement data models, data marts, and data warehouses to support business intelligence and analytics.\n"
     ]
    }
   ],
   "source": [
    "def clean_whitespace(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "def split_into_sentences_or_bullets(text: str) -> List[str]:\n",
    "    if not text:\n",
    "        return []\n",
    "    \n",
    "    lines = [l.strip() for l in text.split(\"\\n\") if l.strip()]\n",
    "    bullets = []\n",
    "\n",
    "    for line in lines:\n",
    "        if re.match(r\"^[-*\\u2022]\\s+\", line):\n",
    "            line = re.sub(r\"^[-*\\u2022]\\s+\", \"\", line)\n",
    "            bullets.append(line)\n",
    "        else:\n",
    "            parts = re.split(r\"(?<=[.!?;])\\s+\", line)\n",
    "            for p in parts:\n",
    "                p = p.strip()\n",
    "                if len(p) > 5:\n",
    "                    bullets.append(p)\n",
    "\n",
    "    bullets = [b for b in bullets if len(b) > 10]\n",
    "    return bullets\n",
    "\n",
    "\n",
    "resume_text = clean_whitespace(resume_raw)\n",
    "jd_text = clean_whitespace(jd_raw)\n",
    "\n",
    "resume_bullets = split_into_sentences_or_bullets(resume_text)\n",
    "jd_bullets = split_into_sentences_or_bullets(jd_text)\n",
    "\n",
    "print(f\"Found {len(resume_bullets)} resume bullets and {len(jd_bullets)} JD bullets.\\n\")\n",
    "\n",
    "print(\"Sample resume bullets:\")\n",
    "for b in resume_bullets[:5]:\n",
    "    print(\"-\", b)\n",
    "\n",
    "print(\"\\nSample JD bullets:\")\n",
    "for b in jd_bullets[:5]:\n",
    "    print(\"-\", b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2413ee19-d7ce-44f1-a01a-a6e407aef68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume skills: ['c', 'flask', 'git', 'java', 'node', 'node.js', 'python', 'tensorflow']\n",
      "JD skills    : ['aws', 'c', 'git', 'power bi', 'python', 'sql', 'tableau']\n",
      "Missing skills: ['aws', 'power bi', 'sql', 'tableau']\n"
     ]
    }
   ],
   "source": [
    "def extract_skills_from_text(text: str, skill_vocab: List[str] = None) -> List[str]:\n",
    "    if skill_vocab is None:\n",
    "        skill_vocab = [\n",
    "            \"python\", \"java\", \"c++\", \"c\", \"sql\", \"excel\", \"pandas\", \"numpy\",\n",
    "            \"tensorflow\", \"pytorch\", \"react\", \"node.js\", \"node\", \"aws\", \"docker\",\n",
    "            \"kubernetes\", \"git\", \"tableau\", \"power bi\", \"matlab\", \"django\", \"flask\"\n",
    "        ]\n",
    "    text_low = text.lower()\n",
    "    found = set()\n",
    "    for s in skill_vocab:\n",
    "        if re.search(r\"\\b\" + re.escape(s.lower()) + r\"\\b\", text_low):\n",
    "            found.add(s)\n",
    "    return sorted(found)\n",
    "\n",
    "\n",
    "resume_skills = extract_skills_from_text(resume_text)\n",
    "jd_skills = extract_skills_from_text(jd_text)\n",
    "missing_skills = [s for s in jd_skills if s not in resume_skills]\n",
    "\n",
    "print(\"Resume skills:\", resume_skills)\n",
    "print(\"JD skills    :\", jd_skills)\n",
    "print(\"Missing skills:\", missing_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a94b19d-532a-4069-b27c-21ce6b7e394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(texts: List[str]) -> np.ndarray:\n",
    "    if not texts:\n",
    "        return np.zeros((0, 384))\n",
    "    emb = embed_model.encode(texts, convert_to_numpy=True, show_progress_bar=False)\n",
    "    return emb\n",
    "\n",
    "def similarity_matrix(A: np.ndarray, B: np.ndarray) -> np.ndarray:\n",
    "    if A.size == 0 or B.size == 0:\n",
    "        return np.zeros((A.shape[0], B.shape[0]))\n",
    "    return cosine_similarity(A, B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7fb4ce3-6e9a-4d42-8597-2f7acf43e2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall match score: 35.16\n",
      "Missing skills: ['aws', 'power bi', 'sql', 'tableau']\n",
      "\n",
      "Top 5 JD lines with their best resume matches:\n",
      "JD: Data Engineer P1 Primary Location: Gurugram , India About the Role: We are seeking a skilled and motivated Snowflake /SQL Developer to join our data engineering team.\n",
      "Best resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git, Google Colab, VS Code, Postman , MongoDB, MySQL\n",
      "Score: 0.381, Weight: 1.0\n",
      "------------------------------------------------------------\n",
      "JD: The ideal candidate will have hands -on experience in designing, developing, and optimizing data pipelines and solutions using Snowflake.\n",
      "Best resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git, Google Colab, VS Code, Postman , MongoDB, MySQL\n",
      "Score: 0.379, Weight: 1.0\n",
      "------------------------------------------------------------\n",
      "JD: You will work closely with cross -functional teams to support data -driven decision -making and ensure the scalability and performance of our data infrastructure.\n",
      "Best resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Score: 0.345, Weight: 1.0\n",
      "------------------------------------------------------------\n",
      "JD: Our tools include Snowflake, SQL, Table au, Power BI Key Responsibilities :  Design and develop scalable data pipelines and ETL processes using Snowflake.\n",
      "Best resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git, Google Colab, VS Code, Postman , MongoDB, MySQL\n",
      "Score: 0.394, Weight: 1.0\n",
      "------------------------------------------------------------\n",
      "JD:  Implement data models, data marts, and data warehouses to support business intelligence and analytics.\n",
      "Best resume bullet:  Used MongoDB to store user data, room inventory, and booking history.\n",
      "Score: 0.395, Weight: 1.0\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def compute_match(resume_bullets: List[str], jd_bullets: List[str]) -> Dict[str, Any]:\n",
    "    emb_resume = get_embeddings(resume_bullets)\n",
    "    emb_jd = get_embeddings(jd_bullets)\n",
    "\n",
    "    sim = similarity_matrix(emb_resume, emb_jd)  # shape: (len(resume), len(jd))\n",
    "    \n",
    "    jd_matches = []\n",
    "    jd_scores = []\n",
    "    weights = []\n",
    "    \n",
    "    for j_idx, jd_line in enumerate(jd_bullets):\n",
    "        if sim.size == 0:\n",
    "            best_score = 0.0\n",
    "            best_idx = None\n",
    "        else:\n",
    "            col = sim[:, j_idx]\n",
    "            best_idx = int(np.argmax(col))\n",
    "            best_score = float(col[best_idx])\n",
    "        \n",
    "        # weight based on wording in JD\n",
    "        w = 1.0\n",
    "        if re.search(r\"\\b(required|must|must have|required experience)\\b\", jd_line, flags=re.I):\n",
    "            w = 2.0\n",
    "        if re.search(r\"\\b(preferred|nice to have|optional)\\b\", jd_line, flags=re.I):\n",
    "            w = 0.8\n",
    "        \n",
    "        jd_matches.append({\n",
    "            \"jd_bullet\": jd_line,\n",
    "            \"best_resume_bullet\": resume_bullets[best_idx] if best_idx is not None and resume_bullets else None,\n",
    "            \"score\": best_score,\n",
    "            \"resume_index\": best_idx,\n",
    "            \"weight\": w\n",
    "        })\n",
    "        jd_scores.append(best_score)\n",
    "        weights.append(w)\n",
    "    \n",
    "    if jd_scores:\n",
    "        overall = float(np.average(jd_scores, weights=weights))\n",
    "    else:\n",
    "        overall = 0.0\n",
    "    \n",
    "    resume_skills = extract_skills_from_text(\"\\n\".join(resume_bullets))\n",
    "    jd_skills = extract_skills_from_text(\"\\n\".join(jd_bullets))\n",
    "    missing_skills = [s for s in jd_skills if s not in resume_skills]\n",
    "    \n",
    "    return {\n",
    "        \"overall_score\": round(overall * 100, 2),   # 0100 scale\n",
    "        \"jd_matches\": jd_matches,\n",
    "        \"resume_skills\": resume_skills,\n",
    "        \"jd_skills\": jd_skills,\n",
    "        \"missing_skills\": missing_skills\n",
    "    }\n",
    "\n",
    "\n",
    "match_report = compute_match(resume_bullets, jd_bullets)\n",
    "\n",
    "print(\"Overall match score:\", match_report[\"overall_score\"])\n",
    "print(\"Missing skills:\", match_report[\"missing_skills\"])\n",
    "\n",
    "print(\"\\nTop 5 JD lines with their best resume matches:\")\n",
    "for item in match_report[\"jd_matches\"][:5]:\n",
    "    print(f\"JD: {item['jd_bullet']}\")\n",
    "    print(f\"Best resume bullet: {item['best_resume_bullet']}\")\n",
    "    print(f\"Score: {item['score']:.3f}, Weight: {item['weight']}\")\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6494be64-0302-4f37-abdf-e534ef5ad5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large-mnli were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\pipelines\\text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict, Any\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification, pipeline\n",
    "import torch\n",
    "\n",
    "sbert_model_name = \"all-MiniLM-L6-v2\"\n",
    "sbert = SentenceTransformer(sbert_model_name)\n",
    "\n",
    "gen_model_name = \"google/flan-t5-small\"  \n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "gen_model = AutoModelForSeq2SeqLM.from_pretrained(gen_model_name)\n",
    "\n",
    "mnli_model_name = \"roberta-large-mnli\" \n",
    "mnli_tokenizer = AutoTokenizer.from_pretrained(mnli_model_name)\n",
    "mnli_model = AutoModelForSequenceClassification.from_pretrained(mnli_model_name)\n",
    "mnli_label_map = {0: \"contradiction\", 1: \"neutral\", 2: \"entailment\"}  \n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "if torch.cuda.is_available():\n",
    "    gen_model = gen_model.to(\"cuda\")\n",
    "    mnli_model = mnli_model.to(\"cuda\")\n",
    "    sbert = sbert.to(\"cuda\")\n",
    "\n",
    "mnli_pipe = pipeline(\"text-classification\", model=mnli_model, tokenizer=mnli_tokenizer, device=0 if torch.cuda.is_available() else -1, return_all_scores=True)\n",
    "\n",
    "def token_set(text: str) -> set:\n",
    "    return set(re.findall(r\"\\w+\", (text or \"\").lower()))\n",
    "\n",
    "def jd_token_overlap_fraction(suggestion: str, jd_text: str) -> float:\n",
    "    s_tokens = token_set(suggestion)\n",
    "    jd_tokens = token_set(jd_text)\n",
    "    if not s_tokens:\n",
    "        return 0.0\n",
    "    return len(s_tokens & jd_tokens) / len(s_tokens)\n",
    "\n",
    "def surface_change_score(original: str, candidate: str) -> float:\n",
    "    o = token_set(original)\n",
    "    c = token_set(candidate)\n",
    "    if not o and not c:\n",
    "        return 0.0\n",
    "    overlap = len(o & c) / (len(o | c) + 1e-9)\n",
    "    return 1.0 - overlap\n",
    "\n",
    "def semantic_similarity(a: str, b: str) -> float:\n",
    "    emb = sbert.encode([a, b], convert_to_numpy=True, show_progress_bar=False)\n",
    "    a_emb, b_emb = emb[0], emb[1]\n",
    "    cos = np.dot(a_emb, b_emb) / (np.linalg.norm(a_emb) * np.linalg.norm(b_emb) + 1e-9)\n",
    "    return float(np.clip(cos, -1.0, 1.0))\n",
    "\n",
    "def entailment_probability(premise: str, hypothesis: str) -> float:\n",
    "    inputs = mnli_tokenizer(premise, hypothesis, return_tensors=\"pt\", truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "        mnli_model.to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        out = mnli_model(**inputs)\n",
    "        logits = out.logits.squeeze().cpu().numpy()\n",
    "        probs = np.exp(logits) / np.exp(logits).sum()\n",
    "        entail_prob = float(probs[2])\n",
    "    return entail_prob\n",
    "\n",
    "def gen_candidates_t5(original_bullet: str, jd_text: str, num_return: int = 4, max_new_tokens: int = 64) -> List[str]:\n",
    "    prompt = (\n",
    "        \"Rewrite the following resume bullet into a single concise, professional sentence, \"\n",
    "        \"using a stronger action verb and clarifying the impact. DO NOT invent new tools or years; \"\n",
    "        \"use ONLY facts present in the original sentence.\\n\\n\"\n",
    "        f\"Original: {original_bullet}\\n\\n\"\n",
    "        \"Rewritten:\"\n",
    "    )\n",
    "    inputs = gen_tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
    "\n",
    "    candidates = []\n",
    "\n",
    "    out = gen_model.generate(**inputs, max_new_tokens=max_new_tokens, num_beams=4, num_return_sequences=1, early_stopping=True)\n",
    "    text = gen_tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "    candidates.append(text)\n",
    "\n",
    "   \n",
    "    for _ in range(max(0, num_return-1)):\n",
    "        out = gen_model.generate(**inputs, do_sample=True, top_p=0.9, top_k=50, temperature=0.8, max_new_tokens=max_new_tokens, num_return_sequences=1)\n",
    "        text = gen_tokenizer.decode(out[0], skip_special_tokens=True).strip()\n",
    "        candidates.append(text)\n",
    "\n",
    "   \n",
    "    uniq = []\n",
    "    for c in candidates:\n",
    "        c = re.sub(r\"^[\\-\\u2022\\*\\s0-9\\.]+\", \"\", c).split(\"\\n\",1)[0].strip()\n",
    "        if c and c not in uniq:\n",
    "            uniq.append(c)\n",
    "    return uniq[:num_return]\n",
    "\n",
    "def simple_rule_based_rewrite(text: str, jd_text: str = \"\") -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    t = text.strip()\n",
    "\n",
    "    if t:\n",
    "        t = t[0].upper() + t[1:]\n",
    "\n",
    "    \n",
    "    t = re.sub(r\"^[\\-\\\\u2022]+\\s\", \"\", t)\n",
    "\n",
    "   \n",
    "    t = t.replace(\"..\", \".\")\n",
    "\n",
    "    return t\n",
    "\n",
    "def advanced_rewrite_bullet(original_bullet: str, jd_text: str, num_candidates: int = 4,\n",
    "                            min_semantic_sim: float = 0.55, max_jd_overlap: float = 0.45,\n",
    "                            min_entailment: float = 0.55, min_surface_change: float = 0.15) -> List[str]:\n",
    "\n",
    "    if not original_bullet or not original_bullet.strip():\n",
    "        return []\n",
    "\n",
    "    candidates = gen_candidates_t5(original_bullet, jd_text, num_return=num_candidates)\n",
    "    candidates.append(simple_rule_based_rewrite(original_bullet, jd_text=jd_text))\n",
    "    scored = []\n",
    "    orig = original_bullet\n",
    "    for cand in candidates:\n",
    "        if cand.strip().lower() == orig.strip().lower():\n",
    "            continue\n",
    "\n",
    "        jd_overlap = jd_token_overlap_fraction(cand, jd_text)\n",
    "        if jd_overlap > max_jd_overlap:\n",
    "            continue\n",
    "\n",
    "        semsim = semantic_similarity(orig, cand)\n",
    "        if semsim < min_semantic_sim:\n",
    "            continue\n",
    "\n",
    "        surf = surface_change_score(orig, cand)\n",
    "        if surf < min_surface_change:\n",
    "            continue\n",
    "\n",
    "        ent_prob = entailment_probability(orig, cand)\n",
    "        if ent_prob < min_entailment:\n",
    "            continue\n",
    "        score = 0.5 * ent_prob + 0.3 * semsim + 0.2 * surf\n",
    "        scored.append({\"candidate\": cand, \"score\": score, \"ent\": ent_prob, \"sem\": semsim, \"surf\": surf, \"jd_overlap\": jd_overlap})\n",
    "\n",
    "    scored_sorted = sorted(scored, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "    if not scored_sorted:\n",
    "        fallback = simple_rule_based_rewrite(original_bullet, jd_text=jd_text)\n",
    "        return [fallback]\n",
    "\n",
    "    results = []\n",
    "    seen = set()\n",
    "    for item in scored_sorted:\n",
    "        c = item[\"candidate\"].strip()\n",
    "        low = c.lower()\n",
    "        if low not in seen:\n",
    "            results.append(c)\n",
    "            seen.add(low)\n",
    "        if len(results) >= 2:\n",
    "            break\n",
    "\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "571cdd7b-a0c7-4809-8a61-3648cc37f878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch rewrites from match_report ===\n",
      "\n",
      "IDX 0  | score=0.381\n",
      "JD (snippet): Data Engineer P1 Primary Location: Gurugram , India About the Role: We are seeking a skilled and motivated Snowflake /SQL Developer to join our data engineering team.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 10.68s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks /Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 1  | score=0.379\n",
      "JD (snippet): The ideal candidate will have hands -on experience in designing, developing, and optimizing data pipelines and solutions using Snowflake.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (1) [took 9.09s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 2  | score=0.345\n",
      "JD (snippet): You will work closely with cross -functional teams to support data -driven decision -making and ensure the scalability and performance of our data infrastructure.\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (2) [took 3.25s]:\n",
      "  1. Streamlit Cloud was tested on 200+ documents.\n",
      "  2. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 3  | score=0.394\n",
      "JD (snippet): Our tools include Snowflake, SQL, Table au, Power BI Key Responsibilities :  Design and develop scalable data pipelines and ETL processes using Snowflake.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 10.39s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js, TensorFlow, Keras, Librosa, Gradio, Flask , Sci\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 4  | score=0.395\n",
      "JD (snippet):  Implement data models, data marts, and data warehouses to support business intelligence and analytics.\n",
      "Original resume bullet:  Used MongoDB to store user data, room inventory, and booking history.\n",
      "Candidates (1) [took 2.43s]:\n",
      "  1.  Used MongoDB to store user data, room inventory, and booking history.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 5  | score=0.242\n",
      "JD (snippet):  Optimize Snowflake performance through c lustering, partitioning, and query tuning.\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (1) [took 3.28s]:\n",
      "  1. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 6  | score=0.281\n",
      "JD (snippet):  Collaborate with data analysts, business stakeholders, and other developers to understand data requirements.\n",
      "Original resume bullet:  Gained hands -on experience in AI and Cloud technologies.\n",
      "Candidates (1) [took 2.17s]:\n",
      "  1.  Gained hands -on experience in AI and Cloud technologies.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 7  | score=0.298\n",
      "JD (snippet):  Ensure data quality, integrity, and security across all Snowflake environments.\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (2) [took 3.13s]:\n",
      "  1. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "  2. Streamlit Cloud was tested on 200+ documents including research papers and reports.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 8  | score=0.367\n",
      "JD (snippet):  Automate data workflows and integrate Snowflake with other tools (e.g., dbt, Airflow, Azure/AWS/GCP).\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (1) [took 3.16s]:\n",
      "  1. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 9  | score=0.362\n",
      "JD (snippet):  Monitor and troubleshoot data pipeline issues and provide timely resolutions.\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (1) [took 3.05s]:\n",
      "  1. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 10  | score=0.482\n",
      "JD (snippet): Requirements :  BTech/MTech in Computer Science/Electrical engineering or equivalent experience, with a strong software development background.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 9.13s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, CSS / CSS Frameworks/Libraries: Node.js, Express.js, TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 11  | score=0.272\n",
      "JD (snippet):  02 years of experience working with Snowflake in a professional setting.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 10.13s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks /Libraries: Node.js, Express.js, TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 12  | score=0.306\n",
      "JD (snippet):  Strong SQL skills and experience with data modeling concepts.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 9.97s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js, TensorFlow, Keras, Librosa, Gradio, Flask , Sci\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 13  | score=0.454\n",
      "JD (snippet):  Experience with ETL tools and frameworks (e.g., Informatica, Talend, dbt, Apache Airflow).\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 9.93s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS , Node.js , Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 14  | score=0.442\n",
      "JD (snippet):  Familiarity with cloud platforms (AWS, Azure, or GCP) and their data services.\n",
      "Original resume bullet:  Gained hands -on experience in AI and Cloud technologies.\n",
      "Candidates (1) [took 2.21s]:\n",
      "  1.  Gained hands -on experience in AI and Cloud technologies.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 15  | score=0.405\n",
      "JD (snippet):  Understanding of data warehousing principles and best practices.\n",
      "Original resume bullet:  Used MongoDB to store user data, room inventory, and booking history.\n",
      "Candidates (1) [took 2.46s]:\n",
      "  1.  Used MongoDB to store user data, room inventory, and booking history.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 16  | score=0.248\n",
      "JD (snippet):  Experience with versi on control systems (e.g., Git) and CI/CD pipelines.\n",
      "Original resume bullet:  Deployed on Streamlit Cloud, tested on 200+ documents including research papers and reports.\n",
      "Candidates (2) [took 3.34s]:\n",
      "  1. Deployed on Streamlit Cloud, tested on 200+ documents.\n",
      "  2. Streamlit Cloud was tested on 200+ documents including research papers and reports.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 17  | score=0.338\n",
      "JD (snippet):  Excellent problem -solving and communication skills.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (2) [took 9.98s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "  2. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 18  | score=0.327\n",
      "JD (snippet): Preferred Qualifications :  Snowflake certification(s) is a plus.\n",
      "Original resume bullet: Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML /CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask , Scikit -learn Tools & Platforms: Git,...\n",
      "Candidates (1) [took 7.30s]:\n",
      "  1. Technical Skills Languages: Python, Java, JavaScript, C/C++ , HTML / CSS Frameworks/Libraries: Node.js, Express.js , TensorFlow, Keras, Librosa, Gradio, Flask ,\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 20  | score=0.353\n",
      "JD (snippet):  Knowledge of BI tools like Tableau or Power BI.\n",
      "Original resume bullet:  Used MongoDB to store user data, room inventory, and booking history.\n",
      "Candidates (1) [took 2.59s]:\n",
      "  1.  Used MongoDB to store user data, room inventory, and booking history.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 21  | score=0.314\n",
      "JD (snippet):  Exposure to Agile methodologies and DevOps practices.\n",
      "Original resume bullet:  Gained hands -on experience in AI and Cloud technologies.\n",
      "Candidates (1) [took 2.14s]:\n",
      "  1.  Gained hands -on experience in AI and Cloud technologies.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 22  | score=0.260\n",
      "JD (snippet):  Supply Chain/ Procurement functional Knowledge is a Plus.\n",
      "Original resume bullet:  Gained hands -on experience in AI and Cloud technologies.\n",
      "Candidates (1) [took 2.20s]:\n",
      "  1.  Gained hands -on experience in AI and Cloud technologies.\n",
      "--------------------------------------------------------------------------------\n",
      "IDX 23  | score=0.185\n",
      "JD (snippet): Working Conditions  Hybrid Work Mode\n",
      "Original resume bullet: Anubhav Singh anubhavsingh8003 @gmail .com  9536643996 Education Thapar Institute of Engineering and Technology B.E.\n",
      "Candidates (1) [took 4.19s]:\n",
      "  1. Anubhav Singh anubhavsingh8003 @gmail .com  9536643996 Education Thapar Institute of Engineering and Technology B.E.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Processed 23 JD items (low-score threshold 0.55).\n",
      "Saved results to rewrites.csv\n"
     ]
    }
   ],
   "source": [
    "MAX_ITEMS = 50         \n",
    "LOW_SCORE_THRESHOLD = 0.55\n",
    "PRINT_JD_SNIPPET_LEN = 200\n",
    "SAVE_TO_CSV = True\n",
    "CSV_PATH = \"rewrites.csv\"\n",
    "\n",
    "def print_rewrites_for_test():\n",
    "    test_bullet = \"Developed a machine learning model in Python to predict customer churn.\"\n",
    "    test_jd = \"We are looking for a Data Scientist with experience in Python, machine learning, and predictive modeling.\"\n",
    "    print(\"=== Single TEST example ===\")\n",
    "    print(\"Original:\", test_bullet)\n",
    "    t0 = time.time()\n",
    "    try:\n",
    "        res = advanced_rewrite_bullet(test_bullet, test_jd, num_candidates=5)\n",
    "    except Exception as e:\n",
    "        print(\"advanced_rewrite_bullet failed:\", e)\n",
    "        return\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Generated {len(res)} candidate(s) in {dt:.2f}s:\")\n",
    "    for r in res:\n",
    "        print(\" -\", r)\n",
    "    print(\"=\"*80, \"\\n\")\n",
    "\n",
    "def print_rewrites_from_match_report(match_report, jd_text=None, max_items=MAX_ITEMS, save_csv=SAVE_TO_CSV):\n",
    "    if not match_report or 'jd_matches' not in match_report:\n",
    "        print(\"No match_report['jd_matches'] found. Please ensure match_report exists.\")\n",
    "        return\n",
    "\n",
    "    rows = []\n",
    "    count = 0\n",
    "    print(\"=== Batch rewrites from match_report ===\\n\")\n",
    "    for idx, item in enumerate(match_report['jd_matches']):\n",
    "        if count >= max_items:\n",
    "            break\n",
    "        score = item.get('score', 0.0)\n",
    "        if score >= LOW_SCORE_THRESHOLD:\n",
    "            continue  \n",
    "\n",
    "        jd_bullet = item.get('jd_bullet', '') or ''\n",
    "        orig = item.get('best_resume_bullet') or ''\n",
    "        if not orig:\n",
    "            continue\n",
    "\n",
    "        context_jd = jd_text if jd_text else jd_bullet\n",
    "\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            candidates = advanced_rewrite_bullet(orig, context_jd, num_candidates=5)\n",
    "            elapsed = time.time() - t0\n",
    "        except Exception as e:\n",
    "            print(f\"[IDX {idx}] advanced_rewrite_bullet failed: {e}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"IDX {idx}  | score={score:.3f}\")\n",
    "        print(\"JD (snippet):\", shorten(jd_bullet, width=PRINT_JD_SNIPPET_LEN, placeholder=\"...\"))\n",
    "        print(\"Original resume bullet:\", shorten(orig, width=200, placeholder=\"...\"))\n",
    "        print(f\"Candidates ({len(candidates)}) [took {elapsed:.2f}s]:\")\n",
    "        for i, c in enumerate(candidates, 1):\n",
    "            print(f\"  {i}. {c}\")\n",
    "        print(\"-\"*80)\n",
    "\n",
    "        rows.append({\n",
    "            \"idx\": idx,\n",
    "            \"score\": score,\n",
    "            \"jd_bullet\": jd_bullet,\n",
    "            \"original_bullet\": orig,\n",
    "            \"candidates\": \" ||| \".join(candidates)\n",
    "        })\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    print(f\"\\nProcessed {count} JD items (low-score threshold {LOW_SCORE_THRESHOLD}).\")\n",
    "\n",
    "    if save_csv and rows:\n",
    "        try:\n",
    "            with open(CSV_PATH, \"w\", newline='', encoding=\"utf-8\") as f:\n",
    "                writer = csv.DictWriter(f, fieldnames=[\"idx\",\"score\",\"jd_bullet\",\"original_bullet\",\"candidates\"])\n",
    "                writer.writeheader()\n",
    "                for r in rows:\n",
    "                    writer.writerow(r)\n",
    "            print(f\"Saved results to {CSV_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to save CSV:\", e)\n",
    "\n",
    "\n",
    "if 'match_report' in globals():\n",
    "    print_rewrites_from_match_report(match_report, jd_text=globals().get('jd_text', None), max_items=MAX_ITEMS, save_csv=SAVE_TO_CSV)\n",
    "else:\n",
    "    print(\"match_report not found in globals(), skipping batch run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f737b7b7-b00f-415b-aab0-1a4aa4ece276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
